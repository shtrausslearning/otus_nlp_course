# **Задача NER**

### **Краткое содержание**
- `NER` 
- подходы для решения 

### **Цели занятия**
- рассмотреть задачу `NER` и области ее применения.

### **Компетенции**

Анализ текстовых данных NLP

- решать задачу распознавания именованных сущностей (`NER`)

### **Практика**


В таблице указано содержание различных проэктов по этой теме 

|`filename`|`contents` |`conclusion`|
|-----------------|-------------------|----------------------| 
| **[preset_NER](https://github.com/shtrausslearning/otus_nlp_course/blob/main/3_Классические%20методы%20NLP/10_Векторные%20представления%20слов%20и%20работа%20с%20предобученными%20эмбедингами/text_embeddings.ipynb)**  <p>  | <p><p> <sub> ![](https://img.shields.io/badge/Project-Information-4169E1)</sub> <p><p> В этом проекте мы воспользуемся готовым инструментов для распознования именованных сущностей `natasha`. Библиоека работает только с русским языком. В русском часто всречаются и именованные сущности с латинскими буквами, поэтому воспользуемся регулярными выражением и лематизацией для того чтобы дополнить результаты NER c `natasha`  <p>  <sub>![](https://img.shields.io/badge/Input-Data-DE3163)</sub> <p>  Для входных данных мы используем `txt` формат для тестирования самого метода и написания вспомогательных функции, после чего мы загружаем главные данные отзывов банка используя `csv` <p> <sub>![](https://img.shields.io/badge/Text-Preprocessing-9ACD32)</sub> <p> Предобработка текста для двух подходов немного различается, используя `natasha` мы можем токенизировать и привести токены в нормальный формат используя `doc`. C регулярками мы токенизируем документ используя `re.findall` и лематизируем найдены именованные сущности используя `pymorphy2` <p> | ![](https://img.shields.io/badge/NLP-pipeline-FF7F50) <p><p>В этом проекте мы создали `pipline` для выделения именованных сущностей в корпусе документов используя готовые инструменты `natasha` и `re` | 
| **[gru_NER](https://github.com/shtrausslearning/otus_nlp_course/blob/main/3_Классические%20методы%20NLP/11_Задача%20NER/gru_NER.ipynb)** | <p><p><picture><img alt="Image Alt Text" src="https://img.shields.io/badge/Project-Information-4169E1"></picture> <p> В этом проекте мы обучаем нейросетевую `NER` модель на основе `GRU`, которая может распозновать именнованные сущности используя `BIO` разметку на отзывах пользователей автомобилей. В отличий от предыдущего ноута понятие `NER` используется немного более абстрактно, нас интересует любые разметки которые мы разметим в тексте, а не только имена и тд. В качестве разметок используем тэги которые описывают качество автомобиля (eg. `appearance`, `comfort`, `costs`, и тд.). Модель учится классифицировать в тексте токены которые относятся к одному из тэговых классов. Распознование таких меток удобно для быстого понимания содержания отзыва. <p> <picture><img alt="Image Alt Text" src="https://img.shields.io/badge/Input-Data-DE3163"></picture> <p> Для входных данных мы используем `xml` отзывов автомобилистов. Для каждого отзыва у нас есть раздел `aspect` в котором хранятся разметки в отзыве (index начало и конца) <p> <picture><img alt="Image Alt Text" src="https://img.shields.io/badge/Text-Preprocessing-9ACD32"></picture> <p> В данных у нас разметки для отдельных тэгах. В начале, разбиваем документ на части используя регулярные выражения и соответсвенно корректируем расположение разметок, далее создаем дополнительные тэги для всех токенов которые не имеют в отзыве разметку, сгрупируем их в метку `other`. Далее мы токенизируем предложение и создаем `BIO` тэги (только B,I). Имея токены, мы их лемматизируем с `pymorphy2` и преврощаем их в векторное представление используя предобученные `fasttext` вектора. <p> <picture><img alt="Image Alt Text" src="https://img.shields.io/badge/Modeling-Process-3CB371"></picture> <p> В качестве модели воспользуемся стациораными эмбедингами и однослойной bidirectional GRU c `HIDDEN_DIM` (12) и линейной проекции тоже с размерностью (12), конкатинируем два слоя получаем hidden state размерности (36), на выходе еще один линейный слой который на выходе имеет размерность `TAGSET_SIZE` (16), и считаем softmax для распределение вероятностей принадлежности классов `log_softmax`. Класс использует внешнюю функцию `vectorize_word_seq` для испорта данных в модель. В качестве функции потерь используем `NLLLoss` и оптимизатор стохастический градиентный спуск `SGD`. | <p> <picture><img alt="Image Alt Text" src="https://img.shields.io/badge/NLP-pipeline-FF7F50"></picture> <p> В этом пректе мы создали нейросетевую модель `NER` которая может распозновать именнованные сущности в отзывах автомобилей. Создали полноценную `pipeline`  для `NER` тэгера. <p> |
